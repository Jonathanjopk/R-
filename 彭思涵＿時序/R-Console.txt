> #--------------------------------add package--------------------------------
> library(tseries)

    ‘tseries’ version: 0.10-32

    ‘tseries’ is a package for time series analysis and computational finance.

    See ‘library(help="tseries")’ for details.

> library(timeDate)
警告訊息：
package ‘timeDate’ was built under R version 3.1.2 
> library(forecast)
Loading required package: zoo

Attaching package: ‘zoo’

The following objects are masked from ‘package:base’:

    as.Date, as.Date.numeric

This is forecast 5.6 

> 
> #--------------------------------read data--------------------------------
> tw<-read.table("tw.prn", header=T)     #read original data
> plot.ts(tw$VALUE)
> tw1<-read.table("tw1.prn", header=T)    #read edited data
> plot.ts(tw1$VALUE)
> tw.is<-read.table("IS.prn", header=T)    #read in sample data
> plot.ts(tw.is$VALUE)
> tw.os<-read.table("OS.prn", header=T)    #read out of sample data
> 
> acf(tw.is$VALUE)
> 
> #--------------------------------unit test--------------------------------
> PP.test(tw.is$VALUE)

	Phillips-Perron Unit Root Test

data:  tw.is$VALUE
Dickey-Fuller = -0.9299, Truncation lag parameter = 5, p-value = 0.9485

> adf.test(tw.is$VALUE)

	Augmented Dickey-Fuller Test

data:  tw.is$VALUE
Dickey-Fuller = 1.6499, Lag order = 6, p-value = 0.99
alternative hypothesis: stationary

警告訊息：
In adf.test(tw.is$VALUE) : p-value greater than printed p-value
> 
> #--------------------------------first order difference--------------------------------
> tw1d1<-diff(tw.is$VALUE, lag=1)
> plot.ts(tw1d1)
> tw1d1<-diff(log(tw.is$VALUE), lag=1)      #difference after log
> plot.ts(tw1d1)
> 
> #--------------------------------unit root test--------------------------------
> PP.test(tw1d1)

	Phillips-Perron Unit Root Test

data:  tw1d1
Dickey-Fuller = -29.2321, Truncation lag parameter = 5, p-value = 0.01

> adf.test(tw1d1)

	Augmented Dickey-Fuller Test

data:  tw1d1
Dickey-Fuller = -6.5494, Lag order = 6, p-value = 0.01
alternative hypothesis: stationary

警告訊息：
In adf.test(tw1d1) : p-value smaller than printed p-value
> 
> acf(tw1d1)
> acf(tw1d1, lag=36)
> pacf(tw1d1, lag=36)
> 
> #--------------------------------seasonal difference--------------------------------
> twd12<-diff(tw1d1, lag=12)
> plot.ts(twd12)
> acf(twd12, lag=36)
> pacf(twd12, lag=36)
> 
> #--------------------------------model selection--------------------------------
> tw.log<-log(tw.is$VALUE)
> x1<-arima(tw.log, order=c(1,1,1), seasonal=list(order=c(1,1,1), period=12))
> x2<-arima(tw.log, order=c(0,1,0), seasonal=list(order=c(1,1,1), period=12))
> x2<-arima(tw.log, order=c(1,1,1), seasonal=list(order=c(0,1,0), period=12))
> x3<-arima(tw.log, order=c(1,1,1), seasonal=list(order=c(0,1,1), period=12))
> x4<-arima(tw.log, order=c(1,1,1), seasonal=list(order=c(2,1,1), period=12))
> x5<-arima(tw.log, order=c(2,1,1), seasonal=list(order=c(2,1,1), period=12))
> x6<-arima(tw.log, order=c(3,1,1), seasonal=list(order=c(2,1,1), period=12))
> x7<-arima(tw.log, order=c(3,1,1), seasonal=list(order=c(1,1,1), period=12))
> 
> x1
Series: tw.log 
ARIMA(1,1,1)(1,1,1)[12]                    

Coefficients:
          ar1      ma1     sar1     sma1
      -0.3761  -0.2005  -0.2058  -0.7647
s.e.   0.0889   0.0845   0.0745   0.0562

sigma^2 estimated as 0.002141:  log likelihood=407.75
AIC=-805.5   AICc=-805.26   BIC=-787.87
> x2
Series: tw.log 
ARIMA(1,1,1)(0,1,0)[12]                    

Coefficients:
          ar1      ma1
      -0.3224  -0.3169
s.e.   0.0842   0.0733

sigma^2 estimated as 0.004219:  log likelihood=329.89
AIC=-653.77   AICc=-653.68   BIC=-643.2
> x3
Series: tw.log 
ARIMA(1,1,1)(0,1,1)[12]                    

Coefficients:
          ar1      ma1     sma1
      -0.3531  -0.2271  -0.8388
s.e.   0.0894   0.0835   0.0423

sigma^2 estimated as 0.002203:  log likelihood=404.16
AIC=-800.32   AICc=-800.16   BIC=-786.22
> x4
Series: tw.log 
ARIMA(1,1,1)(2,1,1)[12]                    

Coefficients:
          ar1      ma1     sar1     sar2     sma1
      -0.3735  -0.1945  -0.3078  -0.1437  -0.6772
s.e.   0.0898   0.0852   0.1032   0.0894   0.0942

sigma^2 estimated as 0.002119:  log likelihood=409.04
AIC=-806.08   AICc=-805.74   BIC=-784.93
> x5
Series: tw.log 
ARIMA(2,1,1)(2,1,1)[12]                    

Coefficients:
          ar1      ar2     ma1     sar1     sar2     sma1
      -1.0337  -0.4226  0.4429  -0.2778  -0.1330  -0.6903
s.e.   0.1595   0.0844  0.1675   0.0986   0.0862   0.0862

sigma^2 estimated as 0.002046:  log likelihood=413.5
AIC=-813.01   AICc=-812.55   BIC=-788.33
> x6
Series: tw.log 
ARIMA(3,1,1)(2,1,1)[12]                    

Coefficients:
         ar1     ar2     ar3      ma1     sar1     sar2     sma1
      0.0480  0.2933  0.2869  -0.6512  -0.3272  -0.1579  -0.6453
s.e.  0.1896  0.1119  0.0611   0.1945   0.1064   0.0903   0.0979

sigma^2 estimated as 0.001991:  log likelihood=417.19
AIC=-818.39   AICc=-817.79   BIC=-790.18
> x7
Series: tw.log 
ARIMA(3,1,1)(1,1,1)[12]                    

Coefficients:
         ar1     ar2     ar3      ma1     sar1     sma1
      0.0430  0.2948  0.2865  -0.6556  -0.2143  -0.7424
s.e.  0.1933  0.1148  0.0613   0.1984   0.0755   0.0556

sigma^2 estimated as 0.002017:  log likelihood=415.65
AIC=-817.3   AICc=-816.84   BIC=-792.63
> 
> #--------------------------------Q test--------------------------------
> Box.test(x1$resid)

	Box-Pierce test

data:  x1$resid
X-squared = 0.1326, df = 1, p-value = 0.7157

> Box.test(x1$resid, h=12)
錯誤在Box.test(x1$resid, h = 12) : unused argument (h = 12)
> Box.test(x1$resid, lag=12)

	Box-Pierce test

data:  x1$resid
X-squared = 25.7103, df = 12, p-value = 0.01179

> Box.test(x1$resid, lag=24)

	Box-Pierce test

data:  x1$resid
X-squared = 35.3439, df = 24, p-value = 0.06346

> Box.test(x1$resid, lag=36)

	Box-Pierce test

data:  x1$resid
X-squared = 45.7491, df = 36, p-value = 0.128

> Box.test(x2$resid)

	Box-Pierce test

data:  x2$resid
X-squared = 0.2465, df = 1, p-value = 0.6195

> Box.test(x2$resid, lag=12)

	Box-Pierce test

data:  x2$resid
X-squared = 109.8896, df = 12, p-value < 2.2e-16

> Box.test(x2$resid, lag=24)

	Box-Pierce test

data:  x2$resid
X-squared = 123.2732, df = 24, p-value = 2.554e-15

> Box.test(x2$resid, lag=36)

	Box-Pierce test

data:  x2$resid
X-squared = 144.5337, df = 36, p-value = 5.995e-15

> Box.test(x3$resid)

	Box-Pierce test

data:  x3$resid
X-squared = 0.1461, df = 1, p-value = 0.7023

> Box.test(x3$resid, lag=12,24,36)
錯誤在match.arg(type) : 'arg' must be NULL or a character vector
> Box.test(x3$resid, lag=12)

	Box-Pierce test

data:  x3$resid
X-squared = 30.9253, df = 12, p-value = 0.002022

> Box.test(x3$resid, lag=24)

	Box-Pierce test

data:  x3$resid
X-squared = 40.7645, df = 24, p-value = 0.01768

> Box.test(x3$resid, lag=36)

	Box-Pierce test

data:  x3$resid
X-squared = 55.4258, df = 36, p-value = 0.02027

> Box.test(x4$resid)

	Box-Pierce test

data:  x4$resid
X-squared = 0.134, df = 1, p-value = 0.7143

> Box.test(x4$resid, lag=12)

	Box-Pierce test

data:  x4$resid
X-squared = 24.9762, df = 12, p-value = 0.01494

> Box.test(x4$resid, lag=24)

	Box-Pierce test

data:  x4$resid
X-squared = 36.1895, df = 24, p-value = 0.05261

> Box.test(x4$resid, lag=36)

	Box-Pierce test

data:  x4$resid
X-squared = 42.9737, df = 36, p-value = 0.1972

> Box.test(x5$resid)

	Box-Pierce test

data:  x5$resid
X-squared = 0.0606, df = 1, p-value = 0.8055

> Box.test(x5$resid, lag=12)

	Box-Pierce test

data:  x5$resid
X-squared = 13.928, df = 12, p-value = 0.3053

> Box.test(x5$resid, lag=24)

	Box-Pierce test

data:  x5$resid
X-squared = 25.3319, df = 24, p-value = 0.3879

> Box.test(x5$resid, lag=36)

	Box-Pierce test

data:  x5$resid
X-squared = 34.8189, df = 36, p-value = 0.5247

> Box.test(x6$resid)

	Box-Pierce test

data:  x6$resid
X-squared = 3e-04, df = 1, p-value = 0.9855

> Box.test(x6$resid, lag=12)

	Box-Pierce test

data:  x6$resid
X-squared = 6.7644, df = 12, p-value = 0.8728

> Box.test(x6$resid, lag=24)

	Box-Pierce test

data:  x6$resid
X-squared = 19.2603, df = 24, p-value = 0.738

> Box.test(x6$resid, lag=36)

	Box-Pierce test

data:  x6$resid
X-squared = 29.162, df = 36, p-value = 0.7833

> Box.test(x7$resid)

	Box-Pierce test

data:  x7$resid
X-squared = 0.0036, df = 1, p-value = 0.9521

> Box.test(x7$resid, lag=12)

	Box-Pierce test

data:  x7$resid
X-squared = 7.4238, df = 12, p-value = 0.8284

> Box.test(x7$resid, lag=24)

	Box-Pierce test

data:  x7$resid
X-squared = 18.173, df = 24, p-value = 0.7945

> Box.test(x7$resid, lag=36)

	Box-Pierce test

data:  x7$resid
X-squared = 31.1109, df = 36, p-value = 0.7002

> 
> #--------------------------------model predict--------------------------------
> summary(forecast(x1), h=34)

Forecast method: ARIMA(1,1,1)(1,1,1)[12]                   

Model Information:
Series: tw.log 
ARIMA(1,1,1)(1,1,1)[12]                    

Coefficients:
          ar1      ma1     sar1     sma1
      -0.3761  -0.2005  -0.2058  -0.7647
s.e.   0.0889   0.0845   0.0745   0.0562

sigma^2 estimated as 0.002141:  log likelihood=407.75
AIC=-805.5   AICc=-805.26   BIC=-787.87

Error measures:
                      ME       RMSE        MAE        MPE      MAPE      MASE        ACF1
Training set 0.001839552 0.04515559 0.03487973 0.01868076 0.3883049 0.6322412 -0.02241485

Forecasts:
    Point Forecast     Lo 80    Hi 80     Lo 95    Hi 95
265       10.03302  9.973719 10.09233  9.942325 10.12372
266        9.99029  9.925889 10.05469  9.891797 10.08878
267       10.16798 10.093224 10.24275 10.053648 10.28232
268       10.16857 10.086797 10.25034 10.043509 10.29363
269       10.16743 10.078504 10.25636 10.031427 10.30344
270       10.16501 10.069701 10.26031 10.019250 10.31076
271       10.18077 10.079401 10.28213 10.025742 10.33579
272       10.19070 10.083649 10.29775 10.026979 10.35442
273       10.21915 10.106690 10.33162 10.047155 10.39115
274       10.26116 10.143535 10.37878 10.081270 10.44104
275       10.23504 10.112473 10.35760 10.047591 10.42248
276       10.22955 10.102231 10.35686 10.034835 10.42426
277       10.15919 10.026826 10.29155  9.956757 10.36162
278       10.09658  9.959618 10.23354  9.887114 10.30605
279       10.29101 10.149503 10.43252 10.074593 10.50743
280       10.29033 10.144450 10.43620 10.067228 10.51343
281       10.27634 10.126206 10.42647 10.046731 10.50594
282       10.28603 10.131764 10.44029 10.050101 10.52195
283       10.29346 10.135167 10.45175 10.051373 10.53554
284       10.32081 10.158590 10.48302 10.072718 10.56889
285       10.35799 10.191943 10.52404 10.104042 10.61194
286       10.39845 10.228649 10.56824 10.138765 10.65813
287       10.37764 10.204181 10.55110 10.112356 10.64293
288       10.37316 10.196105 10.55021 10.102380 10.64393
> 
> summary(forecast(x6), h=34)

Forecast method: ARIMA(3,1,1)(2,1,1)[12]                   

Model Information:
Series: tw.log 
ARIMA(3,1,1)(2,1,1)[12]                    

Coefficients:
         ar1     ar2     ar3      ma1     sar1     sar2     sma1
      0.0480  0.2933  0.2869  -0.6512  -0.3272  -0.1579  -0.6453
s.e.  0.1896  0.1119  0.0611   0.1945   0.1064   0.0903   0.0979

sigma^2 estimated as 0.001991:  log likelihood=417.19
AIC=-818.39   AICc=-817.79   BIC=-790.18

Error measures:
                      ME       RMSE        MAE        MPE      MAPE      MASE        ACF1
Training set 0.001637392 0.04354294 0.03357342 0.01655161 0.3739035 0.6085627 0.001120489

Forecasts:
    Point Forecast     Lo 80    Hi 80     Lo 95    Hi 95
265       10.05115  9.993969 10.10833  9.963698 10.13861
266       10.00035  9.938831 10.06187  9.906264 10.09444
267       10.18935 10.117137 10.26155 10.078912 10.29978
268       10.19326 10.108268 10.27825 10.063278 10.32324
269       10.20002 10.106223 10.29383 10.056568 10.34348
270       10.19977 10.095368 10.30418 10.040099 10.35945
271       10.22041 10.106053 10.33476 10.045519 10.39529
272       10.23441 10.110771 10.35805 10.045319 10.42351
273       10.26423 10.131224 10.39724 10.060812 10.46766
274       10.31276 10.170845 10.45467 10.095720 10.52979
275       10.28390 10.133374 10.43443 10.053689 10.51411
276       10.28114 10.122233 10.44006 10.038111 10.52418
277       10.21023 10.042756 10.37771  9.954099 10.46637
278       10.15960  9.984125 10.33508  9.891234 10.42797
279       10.34882 10.165477 10.53216 10.068422 10.62922
280       10.35575 10.164737 10.54675 10.063623 10.64787
281       10.33966 10.141253 10.53807 10.036222 10.64310
282       10.35161 10.145977 10.55724 10.037122 10.66609
283       10.36707 10.154419 10.57973 10.041846 10.69230
284       10.38706 10.167573 10.60655 10.051384 10.72274
285       10.43026 10.204109 10.65641 10.084391 10.77613
286       10.47384 10.241192 10.70649 10.118035 10.82965
287       10.44977 10.210780 10.68876 10.084266 10.81527
288       10.44761 10.202428 10.69280 10.072635 10.82259
> 
> summary(forecast(x7), h=34)

Forecast method: ARIMA(3,1,1)(1,1,1)[12]                   

Model Information:
Series: tw.log 
ARIMA(3,1,1)(1,1,1)[12]                    

Coefficients:
         ar1     ar2     ar3      ma1     sar1     sma1
      0.0430  0.2948  0.2865  -0.6556  -0.2143  -0.7424
s.e.  0.1933  0.1148  0.0613   0.1984   0.0755   0.0556

sigma^2 estimated as 0.002017:  log likelihood=415.65
AIC=-817.3   AICc=-816.84   BIC=-792.63

Error measures:
                      ME       RMSE        MAE        MPE      MAPE     MASE        ACF1
Training set 0.001547731 0.04382813 0.03372675 0.01567787 0.3755087 0.611342 0.003700726

Forecasts:
    Point Forecast     Lo 80    Hi 80     Lo 95    Hi 95
265       10.04464  9.987079 10.10220  9.956609 10.13267
266       10.00995  9.948225 10.07168  9.915549 10.10435
267       10.19305 10.120691 10.26540 10.082389 10.30370
268       10.19935 10.114404 10.28430 10.069437 10.32926
269       10.20055 10.106979 10.29413 10.057443 10.34367
270       10.20272 10.098689 10.30674 10.043620 10.36181
271       10.22184 10.108060 10.33563 10.047827 10.39586
272       10.23442 10.111523 10.35732 10.046465 10.42238
273       10.26680 10.134709 10.39890 10.064783 10.46882
274       10.31096 10.170139 10.45178 10.095593 10.52633
275       10.28562 10.136350 10.43489 10.057332 10.51390
276       10.28153 10.124045 10.43902 10.040677 10.52239
277       10.21183 10.045650 10.37801  9.957679 10.46598
278       10.14993  9.975824 10.32404  9.883656 10.41621
279       10.34615 10.164169 10.52813 10.067835 10.62446
280       10.34724 10.157564 10.53691 10.057158 10.63731
281       10.33162 10.134556 10.52868 10.030237 10.63300
282       10.34380 10.139493 10.54810 10.031342 10.65625
283       10.35175 10.140414 10.56309 10.028538 10.67497
284       10.38053 10.162348 10.59871 10.046849 10.71421
285       10.42011 10.195248 10.64497 10.076214 10.76400
286       10.46124 10.229867 10.69261 10.107388 10.81508
287       10.44052 10.202797 10.67824 10.076954 10.80408
288       10.43656 10.192634 10.68049 10.063506 10.80962
> 
> x6.1<-forecast(x6, h=34)$mean
> x6.2<-exp(x6.1)
> x6.2
Time Series:
Start = 265 
End = 298 
Frequency = 1 
 [1] 23182.47 22034.19 26618.08 26722.38 26903.86 26897.07 27457.79 27845.09 28687.99 30114.36 29257.80 29177.24 27179.92 25837.97 31220.15 31437.16 30935.49 31307.34 31795.27
[20] 32437.16 33869.19 35377.85 34536.43 34462.05 32147.42 30171.94 36825.21 36987.79 36254.46 36867.42 37231.67 38389.86 40165.18 41925.55
> 
>
> y<-log(tw$VALUE[265:298])
> SSE=sum((y-x6.1)^2)
> RMSE=(SSE/34)^0.5
> RMSE
[1] 0.1268018
> 
> x7.1<-forecast(x7, h=34)$mean
> x7.2<-exp(x7.1)
> x7.2
Time Series:
Start = 265 
End = 298 
Frequency = 1 
 [1] 23031.94 22246.73 26716.73 26885.72 26918.12 26976.37 27497.30 27845.32 28761.81 30060.29 29308.08 29188.55 27223.37 25589.41 31136.88 31170.76 30687.76 31063.73 31311.87
[20] 32226.01 33527.07 34934.71 34218.41 34083.29 31800.96 30054.53 36454.65 36524.67 36080.11 36436.78 36809.99 37748.40 39207.66 40876.69
> 
> SSE=sum((y-x7.2)^2)
> RMSE=(SSE/34)^0.5
> RMSE
[1] 31623.04
> #typo!!!!!!!!!!!!!!!
> 
> SSE=sum((y-x7.1)^2)
> RMSE=(SSE/34)^0.5
> RMSE
[1] 0.1190414
> 
> #--------------------------------forecast--------------------------------
> x8<-arima(tw$VALUE, order=c(3,1,1), seasonal=list(order=c(1,1,1), period=12))
> forecast(x8, h=2)
    Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
370       43134.71 41734.56 44534.85 40993.36 45276.05
371       43928.56 42164.89 45692.24 41231.25 46625.88
> x8.1<-arima(tw1$VALUE, order=c(3,1,1), seasonal=list(order=c(1,1,1), period=12))
> forecast(x8.1, h=73)
    Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
299       31287.69 30525.86 32049.52 30122.57 32452.81
300       30106.19 29246.87 30965.52 28791.97 31420.42
301       29062.84 28048.87 30076.82 27512.11 30613.58
302       25748.43 24573.50 26923.37 23951.52 27545.34
303       30999.72 29723.65 32275.79 29048.14 32951.30
304       30953.56 29556.77 32350.35 28817.36 33089.76
305       30757.97 29259.20 32256.73 28465.81 33050.13
306       31147.65 29555.19 32740.11 28712.20 33583.10
307       31388.34 29702.54 33074.13 28810.14 33966.53
308       32359.32 30588.70 34129.94 29651.40 35067.25
309       32558.16 30705.21 34411.11 29724.32 35392.01
310       32555.33 30623.45 34487.21 29600.77 35509.89
311       32792.28 30672.13 34912.44 29549.79 36034.78
312       31897.88 29659.45 34136.32 28474.49 35321.28
313       30937.18 28567.43 33306.94 27312.96 34561.41
314       27369.64 24867.90 29871.37 23543.57 31195.71
315       32778.98 30164.11 35393.84 28779.88 36778.07
316       32716.22 29984.39 35448.06 28538.24 36894.20
317       32511.92 29670.82 35353.02 28166.83 36857.00
318       32852.87 29907.16 35798.58 28347.80 37357.94
319       33048.23 29999.85 36096.61 28386.14 37710.32
320       34001.46 30855.00 37147.92 29189.36 38813.55
321       34133.30 30891.24 37375.36 29175.00 39091.60
322       33958.09 30623.13 37293.05 28857.71 39058.47
323       34276.51 30744.50 37808.51 28874.77 39678.24
324       33345.31 29679.56 37011.06 27739.02 38951.59
325       32374.60 28561.04 36188.15 26542.26 38206.93
326       28838.67 24875.35 32802.00 22777.29 34900.05
327       34228.08 30132.77 38323.39 27964.85 40491.31
328       34167.61 29935.74 38399.48 27695.53 40639.70
329       33964.33 29603.16 38325.51 27294.49 40634.18
330       34311.25 29825.11 38797.39 27450.30 41172.20
331       34512.28 29902.85 39121.70 27462.77 41561.79
332       35467.65 30739.45 40195.85 28236.49 42698.81
333       35607.78 30763.20 40452.35 28198.63 43016.92
334       35453.85 30495.59 40412.12 27870.84 43036.86
335       35762.20 30601.71 40922.69 27869.91 43654.49
336       34835.55 29525.43 40145.68 26714.42 42956.69
337       33866.08 28394.18 39337.97 25497.53 42234.62
338       30326.25 24690.76 35961.74 21707.51 38944.99
339       35718.12 29934.42 41501.82 26872.71 44563.53
340       35657.37 29721.50 41593.23 26579.24 44735.49
341       35453.96 29372.37 41535.55 26152.98 44754.95
342       35800.14 29576.79 42023.49 26282.35 45317.93
343       36000.47 29636.98 42363.95 26268.36 45732.58
344       36955.58 30456.15 43455.01 27015.56 46895.60
345       37094.68 30461.63 43727.73 26950.30 47239.06
346       36938.13 30174.05 43702.20 26593.37 47282.89
347       37247.72 30273.16 44222.28 26581.05 47914.39
348       36320.51 29181.96 43459.06 25403.04 47237.99
349       35350.88 28037.30 42664.46 24165.72 46536.04
350       31811.54 24321.14 39301.93 20355.97 43267.10
351       37203.10 29549.80 44856.40 25498.39 48907.81
352       37142.39 29322.55 44962.22 25182.99 49101.79
353       36939.00 28958.53 44919.46 24733.93 49144.06
354       37285.27 29147.85 45422.68 24840.16 49730.37
355       37485.68 29192.86 45778.50 24802.90 50168.45
356       38440.82 29996.54 46885.10 25526.41 51355.23
357       38580.05 29986.55 47173.55 25437.43 51722.67
358       38423.82 29683.62 47164.03 25056.83 51790.81
359       38733.26 29773.74 47692.78 25030.86 52435.66
360       37806.12 28669.33 46942.91 23832.61 51779.64
361       36836.51 27512.28 46160.74 22576.33 51096.69
362       33297.11 23783.74 42810.47 18747.67 47846.54
363       38688.71 28998.96 48378.46 23869.51 53507.90
364       38627.99 28758.51 48497.47 23533.92 53722.06
365       38424.60 28380.85 48468.34 23064.01 53785.18
366       38770.86 28556.29 48985.42 23149.02 54392.69
367       38971.26 28587.36 49355.16 23090.45 54852.07
368       39926.40 29376.89 50475.90 23792.32 56060.47
369       40065.61 29352.66 50778.56 23681.56 56449.65
370       39909.34 29035.37 50783.31 23279.03 56539.65
371       40218.80 29116.52 51321.08 23239.32 57198.27
> 
> #--------------------------------END--------------------------------
> 